import os
import sys
import logging
import asyncio

# Zaroori libraries
from pyrogram import Client, filters
from pyrogram.types import Message
from pyrogram.enums import ChatAction

# Google Gemini AI library
import google.generativeai as genai

# --- Logging Setup ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(name)s | %(message)s")
log = logging.getLogger("AIUserBot")

# --- Configuration ---
try:
    API_ID = int(os.environ["API_ID"])
    API_HASH = os.environ["API_HASH"]
    SESSION_STRING = os.environ["SESSION_STRING"]
    GEMINI_API_KEY = os.environ["GEMINI_API_KEY"]
except KeyError as e:
    log.error(f"FATAL: Environment Variable set nahi hai: {e}")
    sys.exit(1)

# --- AI Setup ---
try:
    genai.configure(api_key=GEMINI_API_KEY)
    ai_model = genai.GenerativeModel('gemini-pro')
    log.info("Google Gemini AI model successfully load ho gaya hai.")
except Exception as e:
    log.error(f"AI model load karte waqt error aaya: {e}")
    sys.exit(1)

# --- Userbot Client ---
app = Client(
    "ai_user_bot_session",
    api_id=API_ID,
    api_hash=API_HASH,
    session_string=SESSION_STRING
)

# =================================================================
# === NEW HELPER FUNCTION FOR LONG MESSAGES ===
# =================================================================
async def send_long_message(message: Message, text: str):
    """
    Agar message lamba hai to use 4096 characters ke chunks mein tod kar bhejta hai.
    """
    if len(text) <= 4096:
        await message.reply_text(text)
        return

    log.info("Jawab lamba hai, isliye isse tukdon mein toda ja raha hai...")
    chunks = []
    current_chunk = ""
    # Hum text ko lines ke hisaab se todenge taaki formatting kharaab na ho
    for line in text.splitlines(keepends=True):
        if len(current_chunk) + len(line) > 4096:
            chunks.append(current_chunk)
            current_chunk = ""
        current_chunk += line
    
    if current_chunk:
        chunks.append(current_chunk)

    for i, chunk in enumerate(chunks):
        await message.reply_text(chunk)
        log.info(f"Chunk {i+1}/{len(chunks)} bheja gaya.")
        # Har message ke beech 1 second ka pause, taaki Telegram spam na samjhe
        if i < len(chunks) - 1:
            await asyncio.sleep(1)
# =================================================================


# --- Message Handler ---
@app.on_message(filters.private & ~filters.me)
async def handle_ai_dm(client: Client, message: Message):
    sender_id = message.from_user.id
    if not message.text: # Agar message mein text nahi hai (jaise photo), to ignore karein
        return
        
    log.info(f"Naya DM aaya from User ID {sender_id}: '{message.text}'")

    try:
        await client.send_chat_action(chat_id=sender_id, action=ChatAction.TYPING)

        response = ai_model.generate_content(message.text)
        
        # Jawab bhejte waqt ab naya function use hoga
        await send_long_message(message, response.text)
        
        log.info("AI ne poora jawab bhej diya hai.")

    except Exception as e:
        log.error(f"User {sender_id} ke message ko process karte waqt error: {e}")
        await message.reply_text("Maaf kijiye, abhi main aapke message ko process nahi kar pa raha hoon.")


@app.on_message(filters.command("alive") & filters.me)
async def alive_command(client: Client, message: Message):
    await message.edit_text("âœ… **AI Userbot is running.** (with message splitter)")


# --- Userbot ko chalana ---
if __name__ == "__main__":
    log.info("AI Userbot start ho raha hai...")
    app.run()
